{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Problem Statement\n",
    "Predict if a loan can be approved or not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Hypothesis\n",
    "Analyse which all factors could impact the loan approval. \n",
    "\n",
    "Some of the factors that could impact the loan approval are:\n",
    "1. Salary\n",
    "2. Less loan amount - easily approved\n",
    "3. Lesser monthly repayment amount - easily approved\n",
    "4. Prior loans default rate\n",
    "5. Loan term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Download the dataset and get the train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"/Users/sara/Documents/GitHub/implementations/Loan Prediction/train_ctrUa4K.csv\")\n",
    "test = pd.read_csv(\"/Users/sara/Documents/GitHub/implementations/Loan Prediction/test_lAUu6dG.csv\")\n",
    "\n",
    "train_original = train.copy()\n",
    "test_original = test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Check the various columns in the train and test datasets and determine their datatypes and shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see there are three different formats of datatypes.\n",
    "1. object: Means categorical\n",
    "2. int64: Integer variables\n",
    "3. float64: Numerical with decimal values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"train shape:\",train.shape)\n",
    "print(\"test shape:\",test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train dataset has 614 rows and 13 columns, while test dataset has 367 rows and 12 columns (without the target variable - here loan status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Perform Univariate analysis of the dataset\n",
    "\n",
    "Points to be noted:\n",
    "\n",
    "There are 3 types of features involved:\n",
    "1. Categorical features: Having a category - Gender, Married, Self_Employed, Credit_History, Loan_Status\n",
    "2. Ordinal features: Categorical variables with some order involved - Dependents, Education, Property_Area\n",
    "3. Numerical features: Having numerical values - ApplicantIncome, CoapplicantIncome, LoanAmount, Loan_Amount_Term\n",
    "\n",
    "* For categorical variables, we can use frequency table (with normalization for percentages) and/or bar plots.\n",
    "* For numerical variables, probability density plots can be used to check the distribution - box plots or dist plots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Target Variable - Loan_Status**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Frequency Table of Loan_Status:\",train.Loan_Status.value_counts())\n",
    "print(\"-----------------------------------------------\")\n",
    "print(\"Percentage of Loan_Status:\",train.Loan_Status.value_counts(normalize=True))\n",
    "print(\"-----------------------------------------------\")\n",
    "train.Loan_Status.value_counts().plot.bar()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis: 422 (approx. 69%) loans out of the total 614 loans were approved.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Independent Categorical Variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "\n",
    "plt.subplot(221)\n",
    "train.Gender.value_counts(normalize=True).plot.bar(figsize=(20,10),title=\"Gender\")\n",
    "\n",
    "plt.subplot(222)\n",
    "train.Married.value_counts(normalize=True).plot.bar(title=\"Married\")\n",
    "\n",
    "plt.subplot(223)\n",
    "train.Self_Employed.value_counts(normalize=True).plot.bar(title=\"Self_Employed\")\n",
    "\n",
    "plt.subplot(224)\n",
    "train.Credit_History.value_counts(normalize=True).plot.bar(title=\"Credit_History\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inferences:**\n",
    "\n",
    "**1. 80% of the applicants in the dataset are males.**\n",
    "\n",
    "**2. Around 65% of the applicants are married.**\n",
    "\n",
    "**3. About 15% of the applicants are self employed.**\n",
    "\n",
    "**4. Around 85% of the applicants have repaid their debts.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Independent Ordinal Variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "\n",
    "plt.subplot(141)\n",
    "train.Dependents.value_counts(normalize=True).plot.bar(figsize=(24,6),title=\"Dependents\")\n",
    "\n",
    "plt.subplot(142)\n",
    "train.Education.value_counts(normalize=True).plot.bar(title=\"Education\")\n",
    "\n",
    "plt.subplot(143)\n",
    "train.Property_Area.value_counts(normalize=True).plot.bar(title=\"Property_Area\")\n",
    "\n",
    "plt.subplot(144)\n",
    "train.Loan_Amount_Term.value_counts(normalize=True).plot.bar(title=\"Loan_Amount_Term\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inferences:**\n",
    "\n",
    "**1. Most of the applicants have no dependents.**\n",
    "\n",
    "**2. About 80% of the applicants are graduates.**\n",
    "\n",
    "**3. Most of the applicants are from semiurban area.**\n",
    "\n",
    "**4. More than 80% of the loans are of 1 year terms.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Independent Numerical Variables**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Applicant Income**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "\n",
    "plt.subplot(121)\n",
    "sns.distplot(train.ApplicantIncome)\n",
    "\n",
    "plt.subplot(122)\n",
    "train.ApplicantIncome.plot.box(figsize=(16,5))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inferences:**\n",
    "\n",
    "1. Not normally distributed, right-skewed.\n",
    "2. Box plot shows a lot of outliers - could be the income disparity in the society.\n",
    "\n",
    "Let us check the Income of the applicant versus their education."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.boxplot(column=\"ApplicantIncome\", by=\"Education\")\n",
    "plt.suptitle(\"Applicant Income by Education\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inferences:**\n",
    "\n",
    "From the above plot, it can be seen that more number of graduates have higher income which appear as outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Coapplicant Income**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "\n",
    "plt.subplot(121)\n",
    "sns.distplot(train.CoapplicantIncome)\n",
    "\n",
    "plt.subplot(122)\n",
    "train.CoapplicantIncome.plot.box(figsize=(16,5))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inferences:**\n",
    "\n",
    "1. Not normally distributed, right-skewed - ranging from 0 to 5000.\n",
    "2. Box plot shows a lot of outliers - could be the income disparity in the society - similar to ApplicantIncome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Loan Amount**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "\n",
    "plt.subplot(121)\n",
    "sns.distplot(train.LoanAmount)\n",
    "\n",
    "plt.subplot(122)\n",
    "train.LoanAmount.plot.box(figsize=(16,5))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inferences:**\n",
    "\n",
    "* Lot of outliers, but mostly normally distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Perform Bivariate analysis of the dataset with respect to the target variable\n",
    "\n",
    "Recalling some of the points from our initial hypothesis:\n",
    "\n",
    "1. If loan amount is less, easy approval.\n",
    "2. If prior loan repayment is good, easy approval.\n",
    "3. If income is high, easy approval.\n",
    "4. If loan term is less, easy approval.\n",
    "5. If each term repayment amount is less, easy approval.\n",
    "\n",
    "To verify if the above hypothesis is correct, lets do the bivariate analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Categorical / Ordinal Independent Variables vs Target Variable**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Categorical Independent variables - Gender, Married, Dependents, Education, Self-Employed, Credit_History, Property_Area\n",
    "* Target Variable - Loan_Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gender = pd.crosstab(train.Gender, train.Loan_Status)\n",
    "Married = pd.crosstab(train.Married, train.Loan_Status)\n",
    "Dependents = pd.crosstab(train.Dependents, train.Loan_Status)\n",
    "Education = pd.crosstab(train.Education, train.Loan_Status)\n",
    "Self_Employed = pd.crosstab(train.Self_Employed, train.Loan_Status)\n",
    "Credit_History = pd.crosstab(train.Credit_History, train.Loan_Status)\n",
    "Property_Area = pd.crosstab(train.Property_Area, train.Loan_Status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gender.div(Gender.sum(1).astype(float),axis=0).plot.bar(stacked=True, figsize=(4,4))\n",
    "Married.div(Married.sum(1).astype(float),axis=0).plot.bar(stacked=True, figsize=(4,4))\n",
    "Dependents.div(Dependents.sum(1).astype(float),axis=0).plot(kind=\"bar\", stacked=True, figsize=(4,4))\n",
    "Education.div(Education.sum(1).astype(float),axis=0).plot(kind=\"bar\", stacked=True, figsize=(4,4))\n",
    "Self_Employed.div(Self_Employed.sum(1).astype(float),axis=0).plot(kind=\"bar\", stacked=True, figsize=(4,4))\n",
    "Credit_History.div(Credit_History.sum(1).astype(float),axis=0).plot(kind=\"bar\", stacked=True, figsize=(4,4))\n",
    "Property_Area.div(Property_Area.sum(1).astype(float),axis=0).plot(kind=\"bar\", stacked=True, figsize=(4,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inferences:**\n",
    "\n",
    "**1. Gender: Loan Status is more or less same for male and female applicants.**\n",
    "\n",
    "**2. Married: More number of married applicants have loans approved.**\n",
    "\n",
    "**3. Dependents: Status is similar for applications with 1 or 3+ dependents.**\n",
    "\n",
    "**4. Education: More graduates have their loans approved.**\n",
    "\n",
    "**5. Self-Employed: No particular inference for self-employment.**\n",
    "\n",
    "**6. Credit_History: More number of people with credit_history 1 have their loans approved.**\n",
    "\n",
    "**7. Property_Area: More approvals for Semiurbans areas.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Numerical Independent Variables vs Target Variable**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. ApplicantIncome**\n",
    "\n",
    "We need to find the mean income of people with approved loans vs. mean income of people with unapproved loans and then compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.ApplicantIncome.groupby(train.Loan_Status).mean().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inferences:**\n",
    "\n",
    "* No differences can be seen in mean applicant income.\n",
    "\n",
    "So, lets try making bins for the applicant income based on its values to analyze further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train.ApplicantIncome.max(),train.ApplicantIncome.min(), train.ApplicantIncome.mean())\n",
    "# print(train.ApplicantIncome.value_counts())\n",
    "\n",
    "bins = [0, 2500, 4000, 6000, 81000]\n",
    "groups = ['low', 'average', 'high', 'very high']\n",
    "\n",
    "train['Income_bin'] = pd.cut(train.ApplicantIncome, bins, labels = groups)\n",
    "\n",
    "#Draw the plot\n",
    "\n",
    "Income_bin = pd.crosstab(train.Income_bin, train.Loan_Status)\n",
    "Income_bin.div(Income_bin.sum(1).astype(float),axis=0).plot.bar(stacked=True, figsize = (4,4))\n",
    "\n",
    "plt.xlabel(\"ApplicantIncome\")\n",
    "plt.ylabel(\"Percentage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inferences:**\n",
    "\n",
    "* From the above graph it is clear that the ApplicantIncome has no effect on the Loan approval, as we had initially thought in our hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Coapplicant Income**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.CoapplicantIncome.groupby(train.Loan_Status).mean().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train.CoapplicantIncome.max(),train.CoapplicantIncome.min(), train.CoapplicantIncome.mean())\n",
    "# print(train.CoapplicantIncome.value_counts())\n",
    "\n",
    "bins = [0, 1000, 3000, 4200]\n",
    "groups = ['low', 'average', 'high']\n",
    "\n",
    "train['Coapp_Income_bin'] = pd.cut(train.CoapplicantIncome, bins, labels = groups)\n",
    "\n",
    "#Draw the plot\n",
    "\n",
    "Coapp_Income_bin = pd.crosstab(train.Coapp_Income_bin, train.Loan_Status)\n",
    "Coapp_Income_bin.div(Coapp_Income_bin.sum(1).astype(float),axis=0).plot.bar(stacked=True, figsize = (4,4))\n",
    "\n",
    "plt.xlabel(\"CoapplicantIncome\")\n",
    "plt.ylabel(\"Percentage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The above plot shows that loan approval chances are high, when the coapplicant's income is less, which seems wierd. This could be because, many applicants do not have a coapplicant, so their income remains zero. To surpass this issue, we might have to take the Total Income to analyse this Income field."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Total Income - new feature**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['TotalIncome'] = train.ApplicantIncome + train.CoapplicantIncome\n",
    "print(train.TotalIncome)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train.TotalIncome.min(), train.TotalIncome.max())\n",
    "\n",
    "bins = [0, 2500, 4000, 6000, 81000]\n",
    "groups = [\"Low\", \"Average\", \"High\", \"Very High\"]\n",
    "\n",
    "train[\"Total_Income_bin\"] = pd.cut(train.TotalIncome, bins, labels = groups)\n",
    "# print(train.Total_Income_bin)\n",
    "\n",
    "#Draw the plot\n",
    "\n",
    "Total_Income_bin = pd.crosstab(train.Total_Income_bin, train.Loan_Status)\n",
    "Total_Income_bin.div(Total_Income_bin.sum(1).astype(float),axis=0).plot(kind=\"bar\", stacked=True, figsize=(4,4))\n",
    "\n",
    "plt.xlabel(\"Total_Income\")\n",
    "plt.ylabel(\"Percentage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inferences:**\n",
    "\n",
    "* We can see that less number of loans are getting approved, when the total income is less, compared to the average/high/very high income earning groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Loan Amount**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.LoanAmount.groupby(train.Loan_Status).mean().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train.LoanAmount)\n",
    "# print(train.LoanAmount.min(), train.LoanAmount.max())\n",
    "\n",
    "bins = [0, 100, 200, 700]\n",
    "groups = [\"Low\", \"Average\", \"High\"]\n",
    "\n",
    "train[\"Loan_Amount_bin\"] = pd.cut(train.LoanAmount, bins, labels = groups)\n",
    "Loan_Amount_bin = pd.crosstab(train.Loan_Amount_bin, train.Loan_Status)\n",
    "Loan_Amount_bin.div(Loan_Amount_bin.sum(1).astype(float),axis=0).plot(kind=\"bar\", stacked = True, figsize =(4,4))\n",
    "\n",
    "plt.xlabel(\"LoanAmount\") \n",
    "plt.ylabel(\"Percentage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inferences:**\n",
    "\n",
    "* It can be seen from the above graph that the approved loans is higher for Low and Average Loan Amount as compared to high Loan Amount - which is what we had hypothesized initially."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Find correlation between numerical variables and target variables**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For this, we will drop all the bins we had created for the exploration part, as we do not need these bins in the dataset.\n",
    "\n",
    "* We can change the dependents column from 3+ to 3 to make it a numerical variable.\n",
    "\n",
    "* We can also convert the target variable into 0 and 1 to see if there is a correlation with numerical variables. We can replace N with 0 and Y with 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_hm = train.copy()\n",
    "train_hm = train.drop([\"Loan_ID\", \n",
    "                        #   \"Gender\", \"Married\", \"Education\", \"Self_Employed\", \"Property_Area\",\n",
    "                          \"Income_bin\", \"Coapp_Income_bin\", \"Loan_Amount_bin\", \"Total_Income_bin\", \"TotalIncome\"],axis=1)\n",
    "train = train_hm.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hm[\"Dependents\"].replace(\"3+\", \"3\", inplace=True)\n",
    "# test_hm[\"Dependents\"].replace(\"3+\", \"3\", inplace=True)\n",
    "train_hm[\"Loan_Status\"].replace(\"N\", 0, inplace=True)\n",
    "train_hm[\"Loan_Status\"].replace(\"Y\", 1, inplace=True)\n",
    "train_hm[\"Gender\"].replace(\"Male\", 0, inplace=True)\n",
    "train_hm[\"Gender\"].replace(\"Female\", 1, inplace=True)\n",
    "train_hm[\"Married\"].replace(\"No\", 0, inplace=True)\n",
    "train_hm[\"Married\"].replace(\"Yes\", 1, inplace=True)\n",
    "train_hm[\"Education\"].replace(\"Graduate\", 1, inplace=True)\n",
    "train_hm[\"Education\"].replace(\"Not Graduate\", 0, inplace=True)\n",
    "train_hm[\"Self_Employed\"].replace(\"No\", 0, inplace=True)\n",
    "train_hm[\"Self_Employed\"].replace(\"Yes\", 1, inplace=True)\n",
    "train_hm[\"Property_Area\"].replace(\"Urban\", 2, inplace=True)\n",
    "train_hm[\"Property_Area\"].replace(\"Rural\", 0, inplace=True)\n",
    "train_hm[\"Property_Area\"].replace(\"Semiurban\", 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_hm.Dependents.unique())\n",
    "print(train_hm.Loan_Status.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now lets look at the correlation between the numerical variables.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hm.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hm.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap = train_hm.corr()\n",
    "\n",
    "f, ax = plt.subplots(figsize = (9, 6))\n",
    "sns.heatmap(heatmap, vmax = 0.8, square = True, cmap = \"BuPu\", annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can see that Applicant Income and Loan Amount are most correlated to each other as well as Credit History and Loan Status.**\n",
    "\n",
    "**Loan Amount is also correlated to CoapplicantIncome.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Missing Values Imputation and Outlier treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### There are missing values in Gender, Married, Dependents, Self_Employed, LoanAmount, Loan_Amount_Term, Credit_History"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can fill the missing values in the following ways:\n",
    "\n",
    "1. For categorical variables - using mode\n",
    "2. For numerical variables - using mean or median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Categorical variables - Gender, Married, Dependents, Self_Employed, Credit_History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Gender.fillna(train.Gender.mode()[0], inplace=True)\n",
    "train.Married.fillna(train.Married.mode()[0], inplace=True)\n",
    "train.Dependents.fillna(train.Dependents.mode()[0], inplace=True)\n",
    "train.Self_Employed.fillna(train.Self_Employed.mode()[0], inplace=True)\n",
    "train.Credit_History.fillna(train.Credit_History.mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loan Amount Term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Loan_Amount_Term.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Loan_Amount_Term.fillna(train.Loan_Amount_Term.mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loan Amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.LoanAmount.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.LoanAmount.min())\n",
    "print(train.LoanAmount.mean())\n",
    "print(train.LoanAmount.max())\n",
    "print(train.LoanAmount.median())\n",
    "print(train.LoanAmount.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use median to fill missing values of Loan Amount as we had seen that it had many outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.LoanAmount.fillna(train.LoanAmount.median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Similarly, lets fill test dataset missing values in the same manner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.Gender.fillna(test.Gender.mode()[0], inplace=True)\n",
    "test.Married.fillna(test.Married.mode()[0], inplace=True)\n",
    "test.Dependents.fillna(test.Dependents.mode()[0], inplace=True)\n",
    "test.Self_Employed.fillna(test.Self_Employed.mode()[0], inplace=True)\n",
    "test.Credit_History.fillna(test.Credit_History.mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loan Amount Term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.Loan_Amount_Term.fillna(test.Loan_Amount_Term.mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Numerical - Loan Amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.LoanAmount.fillna(test.LoanAmount.median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier treatment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking log transformation, can help remove skewness as it does not affect small values much but reduces larger values. So we get a distribution similar to a normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Applicant Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(train.ApplicantIncome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.ApplicantIncome_log = np.log(train.ApplicantIncome)\n",
    "sns.distplot(train.ApplicantIncome_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(test.ApplicantIncome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.ApplicantIncome_log = np.log1p(test.ApplicantIncome)\n",
    "sns.distplot(test.ApplicantIncome_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. CoapplicantIncome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(train.CoapplicantIncome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.CoapplicantIncome_log = np.log1p(train.CoapplicantIncome)\n",
    "sns.distplot(train.CoapplicantIncome_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(test.CoapplicantIncome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.CoapplicantIncome_log = np.log1p(test.CoapplicantIncome)\n",
    "sns.distplot(test.CoapplicantIncome_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Loan Amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(train.LoanAmount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.LoanAmount_log = np.log(train.LoanAmount)\n",
    "sns.distplot(train.LoanAmount_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(test.LoanAmount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.LoanAmount_log = np.log(test.LoanAmount)\n",
    "# test.LoanAmount_log.min()\n",
    "sns.distplot(test.LoanAmount_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.LoanAmount_log.hist(bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_eda = train.copy()\n",
    "test_eda = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = train.drop('Loan_ID', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.drop('Loan_ID', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop('Loan_Status', axis=1)\n",
    "y = train['Loan_Status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.get_dummies(train)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.get_dummies(test)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_cv, y_train, y_cv = train_test_split(X, y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_cv = model.predict(X_cv)\n",
    "\n",
    "accuracy_score(y_cv, y_pred_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = model.predict(test)\n",
    "# y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(\"sample_submission_49d68Cx.csv\")\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['Loan_Status'] = y_pred_test\n",
    "submission['Loan_ID'] = test_original['Loan_ID']\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.Loan_Status.replace(1, 'Y', inplace=True)\n",
    "submission.Loan_Status.replace(0, 'N', inplace=True)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(submission, columns=['Loan_ID', 'Loan_Status']).to_csv('logistic.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Stratified KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "sum_score = 0\n",
    "i = 1\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5, random_state=1, shuffle=True)\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "    print('\\n{} of kfold {}'.format(i, kf.n_splits))\n",
    "\n",
    "    xtr, xvl = X.iloc[train_index], X.iloc[test_index]\n",
    "    ytr, yvl = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    model = LogisticRegression(random_state=1)\n",
    "\n",
    "    model.fit(xtr, ytr)\n",
    "\n",
    "    y_pred_vl = model.predict(xvl)\n",
    "\n",
    "    score = accuracy_score(yvl, y_pred_vl)\n",
    "    print(\"accuracy_score\", score)\n",
    "\n",
    "    i+=1\n",
    "\n",
    "    y_pred_test = model.predict(test)\n",
    "    pred = model.predict_proba(xvl)[:, 1]\n",
    "\n",
    "    sum_score += score\n",
    "\n",
    "print(\"\\nMean validation accuracy is:\",sum_score/(i-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(yvl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets check the ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "fpr, tpr, _ = metrics.roc_curve(yvl, pred, pos_label=1)\n",
    "\n",
    "auc = metrics.roc_auc_score(yvl, pred)\n",
    "\n",
    "plt.figure(figsize = (12,8))\n",
    "\n",
    "plt.plot(fpr, tpr, label='validation, auc=' + str(auc))\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['Loan_Status'] = y_pred_test\n",
    "submission['Loan_ID'] = test_original['Loan_ID']\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.Loan_Status.replace(1, 'Y', inplace=True)\n",
    "submission.Loan_Status.replace(0, 'N', inplace=True)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(submission, columns=['Loan_ID', 'Loan_Status']).to_csv('logistic_kfold.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_old = train.copy()\n",
    "test_old = test.copy()\n",
    "X_old = X.copy()\n",
    "y_old = y.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Based on domain knowledge, building new features which could affect the target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Total Income: Applicant Income + Coapplicant Income**\n",
    "\n",
    "**2. EMI: Ratio of Loan Amount with Loan Amount Term**\n",
    "\n",
    "**3. Balance Income: Income left after paying EMI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = train_original.copy()\n",
    "# test = test_original.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Total Income**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['TotalIncome'] = train.ApplicantIncome + train.CoapplicantIncome\n",
    "test['TotalIncome'] = test.ApplicantIncome + test.CoapplicantIncome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(train.TotalIncome)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shifted to the left, so right-skewed. So lets take the log transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['TotalIncome_log'] = np.log(train.TotalIncome)\n",
    "test['TotalIncome_log'] = np.log(test.TotalIncome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(train.TotalIncome_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(test.TotalIncome_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the distribution looks normal and effect of extreme values has been reduced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. EMI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['EMI'] = train['LoanAmount']/train['Loan_Amount_Term']\n",
    "test['EMI'] = test['LoanAmount']/test['Loan_Amount_Term']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(train.EMI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(test.EMI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Balance Income**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['BalanceIncome'] = train['TotalIncome'] - train['EMI']*1000\n",
    "#Multiplying with 1000 to make the units equal\n",
    "\n",
    "test['BalanceIncome'] = test['TotalIncome'] - test['EMI']*1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(train['BalanceIncome'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(test['BalanceIncome'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now we need to drop the features using which we have created these new features, else there will be high correlation between the old features and the newly created features. Also, logistic regression assumes that the variables are not highly correlated. Moreover, noise has to be removed - so removing the correlated variables will reduce the noise also.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(['LoanAmount', 'ApplicantIncome', 'CoapplicantIncome', 'Loan_Amount_Term'], axis=1)\n",
    "test = test.drop(['LoanAmount', 'ApplicantIncome', 'CoapplicantIncome', 'Loan_Amount_Term'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Model building with the newly created features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_new_cols = train.copy()\n",
    "test_new_cols = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.copy()\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop(['Loan_Status_N', 'Loan_Status_Y'], axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_score = 0\n",
    "i = 1\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5, random_state=1, shuffle=True)\n",
    "\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "    print('\\n{} of kfold {}'.format(i, kf.n_splits))\n",
    "\n",
    "    xtr, xvl = X.loc[train_index], X.loc[test_index]\n",
    "    ytr, yvl = y.loc[train_index], y.loc[test_index]\n",
    "\n",
    "    model = LogisticRegression(random_state=1)\n",
    "\n",
    "    model.fit(xtr, ytr)\n",
    "\n",
    "    y_pred_vl = model.predict(xvl)\n",
    "\n",
    "    score = accuracy_score(yvl, y_pred_vl)\n",
    "    print(\"accuracy_score\", score)\n",
    "\n",
    "    i+=1\n",
    "\n",
    "    y_pred_test = model.predict(test)\n",
    "    pred = model.predict_proba(xvl)[:, 1]\n",
    "\n",
    "    sum_score += score\n",
    "\n",
    "print(\"\\nMean validation accuracy is:\", sum_score/(i-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['Loan_Status'] = y_pred_test\n",
    "submission['Loan_ID'] = test_original['Loan_ID']\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.Loan_Status.replace(1, 'Y', inplace=True)\n",
    "submission.Loan_Status.replace(0, 'N', inplace=True)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(submission, columns=['Loan_ID', 'Loan_Status']).to_csv('logistic_kfold_newfeatures.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "sum_score = 0\n",
    "i = 1\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5, random_state=1, shuffle=True)\n",
    "\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "    print('\\n{} of kfold {}'.format(i, kf.n_splits))\n",
    "\n",
    "    xtr, xvl = X.loc[train_index], X.loc[test_index]\n",
    "    ytr, yvl = y[train_index], y[test_index]\n",
    "\n",
    "    model = tree.DecisionTreeClassifier(random_state=1)\n",
    "\n",
    "    model.fit(xtr, ytr)\n",
    "\n",
    "    y_pred_vl = model.predict(xvl)\n",
    "\n",
    "    score = accuracy_score(yvl, y_pred_vl)\n",
    "    print(\"accuracy_score\", score)\n",
    "\n",
    "    i+=1\n",
    "\n",
    "    y_pred_test = model.predict(test)\n",
    "    pred = model.predict_proba(xvl)[:, 1]\n",
    "\n",
    "    sum_score += score\n",
    "\n",
    "print(\"\\nMean validation accuracy is:\", sum_score/(i-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['Loan_Status'] = y_pred_test\n",
    "submission['Loan_ID'] = test_original['Loan_ID']\n",
    "\n",
    "submission.Loan_Status.replace(1, 'Y', inplace=True)\n",
    "submission.Loan_Status.replace(0, 'N', inplace=True)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(submission, columns=['Loan_ID', 'Loan_Status']).to_csv('decision_tree.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "sum_score = 0\n",
    "i = 1\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5, random_state=1, shuffle=True)\n",
    "\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "    print('\\n{} of kfold {}'.format(i, kf.n_splits))\n",
    "\n",
    "    xtr, xvl = X.loc[train_index], X.loc[test_index]\n",
    "    ytr, yvl = y[train_index], y[test_index]\n",
    "\n",
    "    model = RandomForestClassifier(random_state=1)\n",
    "\n",
    "    model.fit(xtr, ytr)\n",
    "\n",
    "    y_pred_vl = model.predict(xvl)\n",
    "\n",
    "    score = accuracy_score(yvl, y_pred_vl)\n",
    "    print(\"accuracy_score\", score)\n",
    "\n",
    "    i+=1\n",
    "\n",
    "    y_pred_test = model.predict(test)\n",
    "    pred = model.predict_proba(xvl)[:, 1]\n",
    "\n",
    "    sum_score += score\n",
    "\n",
    "print(\"\\nMean validation accuracy is:\", sum_score/(i-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean Validation Accuracy for this model is 0.78. Now we can try to improve this by tuning the hyperparameters of the model - using GridSearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "paramgrid = {'max_depth' : list(range(1, 20, 2)), 'n_estimators' : list(range(1, 200, 20))}\n",
    "\n",
    "gridSearch = GridSearchCV(RandomForestClassifier(random_state=1), paramgrid)\n",
    "\n",
    "X_train, X_cv, y_train, y_cv = train_test_split(X, y, test_size = 0.3)\n",
    "\n",
    "#Fit the grid search model\n",
    "gridSearch.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimized value for max_depth is 3 and n_estimators is 41. So, now we can build our model with these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_score = 0\n",
    "i = 1\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5, random_state=1, shuffle=True)\n",
    "\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "    print('\\n{} of kfold {}'.format(i, kf.n_splits))\n",
    "\n",
    "    xtr, xvl = X.loc[train_index], X.loc[test_index]\n",
    "    ytr, yvl = y[train_index], y[test_index]\n",
    "\n",
    "    model = RandomForestClassifier(random_state=1, max_depth=3, n_estimators=121)\n",
    "\n",
    "    model.fit(xtr, ytr)\n",
    "\n",
    "    y_pred_vl = model.predict(xvl)\n",
    "\n",
    "    score = accuracy_score(yvl, y_pred_vl)\n",
    "    print(\"accuracy_score\", score)\n",
    "\n",
    "    i+=1\n",
    "\n",
    "    y_pred_test = model.predict(test)\n",
    "    pred = model.predict_proba(xvl)[:, 1]\n",
    "\n",
    "    sum_score += score\n",
    "\n",
    "print(\"\\nMean validation accuracy is:\", sum_score/(i-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['Loan_Status'] = y_pred_test\n",
    "submission['Loan_ID'] = test_original['Loan_ID']\n",
    "\n",
    "submission.Loan_Status.replace(1, 'Y', inplace=True)\n",
    "submission.Loan_Status.replace(0, 'N', inplace=True)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(submission, columns=['Loan_ID', 'Loan_Status']).to_csv('random_forest.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets find the feature importance now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = pd.Series(model.feature_importances_, index = X.columns)\n",
    "\n",
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances.plot(kind='barh', figsize=(12,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the most important feature is the Credit History followed by the new features we had created - Total Income, Balance Income and EMI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "sum_score = 0\n",
    "i = 1\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5, random_state=1, shuffle=True)\n",
    "\n",
    "y.replace('Y', 1, inplace=True)\n",
    "y.replace('N', 0, inplace=True)\n",
    "\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "    print('\\n{} of kfold {}'.format(i, kf.n_splits))\n",
    "\n",
    "    xtr, xvl = X.loc[train_index], X.loc[test_index]\n",
    "    ytr, yvl = y[train_index], y[test_index]\n",
    "\n",
    "    model = XGBClassifier(max_depth=4, n_estimators=50)\n",
    "\n",
    "    model.fit(xtr, ytr)\n",
    "\n",
    "    y_pred_vl = model.predict(xvl)\n",
    "\n",
    "    score = accuracy_score(yvl, y_pred_vl)\n",
    "    print(\"accuracy_score\", score)\n",
    "\n",
    "    i+=1\n",
    "\n",
    "    y_pred_test = model.predict(test)\n",
    "    pred = model.predict_proba(xvl)[:, 1]\n",
    "\n",
    "    sum_score += score\n",
    "\n",
    "print(\"\\nMean validation accuracy is:\", sum_score/(i-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['Loan_Status'] = y_pred_test\n",
    "submission['Loan_ID'] = test_original['Loan_ID']\n",
    "\n",
    "submission.Loan_Status.replace(1, 'Y', inplace=True)\n",
    "submission.Loan_Status.replace(0, 'N', inplace=True)\n",
    "\n",
    "pd.DataFrame(submission, columns=['Loan_ID', 'Loan_Status']).to_csv('xgb.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "paramgrid = {'max_depth' : list(range(1, 20, 2)), 'n_estimators' : list(range(1, 200, 20))}\n",
    "\n",
    "gridSearch = GridSearchCV(XGBClassifier(random_state=1), paramgrid)\n",
    "\n",
    "X_train, X_cv, y_train, y_cv = train_test_split(X, y, test_size = 0.3)\n",
    "\n",
    "#Fit the grid search model\n",
    "gridSearch.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_score = 0\n",
    "i = 1\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5, random_state=1, shuffle=True)\n",
    "\n",
    "y.replace('Y', 1, inplace=True)\n",
    "y.replace('N', 0, inplace=True)\n",
    "\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "    print('\\n{} of kfold {}'.format(i, kf.n_splits))\n",
    "\n",
    "    xtr, xvl = X.loc[train_index], X.loc[test_index]\n",
    "    ytr, yvl = y[train_index], y[test_index]\n",
    "\n",
    "    model = XGBClassifier(max_depth=1, n_estimators=41)\n",
    "\n",
    "    model.fit(xtr, ytr)\n",
    "\n",
    "    y_pred_vl = model.predict(xvl)\n",
    "\n",
    "    score = accuracy_score(yvl, y_pred_vl)\n",
    "    print(\"accuracy_score\", score)\n",
    "\n",
    "    i+=1\n",
    "\n",
    "    y_pred_test = model.predict(test)\n",
    "    pred = model.predict_proba(xvl)[:, 1]\n",
    "\n",
    "    sum_score += score\n",
    "\n",
    "print(\"\\nMean validation accuracy is:\", sum_score/(i-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['Loan_Status'] = y_pred_test\n",
    "submission['Loan_ID'] = test_original['Loan_ID']\n",
    "\n",
    "submission.Loan_Status.replace(1, 'Y', inplace=True)\n",
    "submission.Loan_Status.replace(0, 'N', inplace=True)\n",
    "\n",
    "pd.DataFrame(submission, columns=['Loan_ID', 'Loan_Status']).to_csv('xgb1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "sum_score = 0\n",
    "i = 1\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5, random_state=1, shuffle=True)\n",
    "\n",
    "y.replace('Y', 1, inplace=True)\n",
    "y.replace('N', 0, inplace=True)\n",
    "\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "    print('\\n{} of kfold {}'.format(i, kf.n_splits))\n",
    "\n",
    "    xtr, xvl = X.loc[train_index], X.loc[test_index]\n",
    "    ytr, yvl = y[train_index], y[test_index]\n",
    "\n",
    "    model = GradientBoostingClassifier(max_depth=3, n_estimators=21)\n",
    "\n",
    "    model.fit(xtr, ytr)\n",
    "\n",
    "    y_pred_vl = model.predict(xvl)\n",
    "\n",
    "    score = accuracy_score(yvl, y_pred_vl)\n",
    "    print(\"accuracy_score\", score)\n",
    "\n",
    "    i+=1\n",
    "\n",
    "    y_pred_test = model.predict(test)\n",
    "    pred = model.predict_proba(xvl)[:, 1]\n",
    "\n",
    "    sum_score += score\n",
    "\n",
    "print(\"\\nMean validation accuracy is:\", sum_score/(i-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['Loan_Status'] = y_pred_test\n",
    "submission['Loan_ID'] = test_original['Loan_ID']\n",
    "\n",
    "submission.Loan_Status.replace(1, 'Y', inplace=True)\n",
    "submission.Loan_Status.replace(0, 'N', inplace=True)\n",
    "\n",
    "pd.DataFrame(submission, columns=['Loan_ID', 'Loan_Status']).to_csv('Gradientboost.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramgrid = {'max_depth' : list(range(1, 20, 2)), 'n_estimators' : list(range(1, 200, 20))}\n",
    "\n",
    "gridSearch = GridSearchCV(GradientBoostingClassifier(random_state=1), paramgrid)\n",
    "\n",
    "X_train, X_cv, y_train, y_cv = train_test_split(X, y, test_size = 0.3)\n",
    "\n",
    "#Fit the grid search model\n",
    "gridSearch.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_score = 0\n",
    "i = 1\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5, random_state=1, shuffle=True)\n",
    "\n",
    "y.replace('Y', 1, inplace=True)\n",
    "y.replace('N', 0, inplace=True)\n",
    "\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "    print('\\n{} of kfold {}'.format(i, kf.n_splits))\n",
    "\n",
    "    xtr, xvl = X.loc[train_index], X.loc[test_index]\n",
    "    ytr, yvl = y[train_index], y[test_index]\n",
    "\n",
    "    model = GradientBoostingClassifier(max_depth=1, n_estimators=21)\n",
    "\n",
    "    model.fit(xtr, ytr)\n",
    "\n",
    "    y_pred_vl = model.predict(xvl)\n",
    "\n",
    "    score = accuracy_score(yvl, y_pred_vl)\n",
    "    print(\"accuracy_score\", score)\n",
    "\n",
    "    i+=1\n",
    "\n",
    "    y_pred_test = model.predict(test)\n",
    "    pred = model.predict_proba(xvl)[:, 1]\n",
    "\n",
    "    sum_score += score\n",
    "\n",
    "print(\"\\nMean validation accuracy is:\", sum_score/(i-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['Loan_Status'] = y_pred_test\n",
    "submission['Loan_ID'] = test_original['Loan_ID']\n",
    "\n",
    "submission.Loan_Status.replace(1, 'Y', inplace=True)\n",
    "submission.Loan_Status.replace(0, 'N', inplace=True)\n",
    "\n",
    "pd.DataFrame(submission, columns=['Loan_ID', 'Loan_Status']).to_csv('Gradientboost1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Combining Applicants with 0, 1, 2, 3 and more dependents and making a new feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_eda.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_eda.Loan_Amount_Term.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_eda.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_eda['Dependents'].replace(\"3+\",3.0,inplace=True)\n",
    "train_eda['Dependents'].replace(\"2\",2.0,inplace=True)\n",
    "train_eda['Dependents'].replace(\"1\",1.0,inplace=True)\n",
    "train_eda['Dependents'].replace(\"0\",0.0,inplace=True)\n",
    "train_eda['Dependents'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eda['Dependents'].replace(\"3+\",3.0,inplace=True)\n",
    "test_eda['Dependents'].replace(\"2\",2.0,inplace=True)\n",
    "test_eda['Dependents'].replace(\"1\",1.0,inplace=True)\n",
    "test_eda['Dependents'].replace(\"0\",0.0,inplace=True)\n",
    "test_eda['Dependents'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_eda['TotalIncome'] = train_eda.ApplicantIncome + train_eda.CoapplicantIncome\n",
    "test_eda['TotalIncome'] = test_eda.ApplicantIncome + test_eda.CoapplicantIncome\n",
    "train_eda['TotalIncome_log'] = np.log(train_eda.TotalIncome)\n",
    "test_eda['TotalIncome_log'] = np.log(test_eda.TotalIncome)\n",
    "train_eda['EMI'] = train_eda['LoanAmount']/train_eda['Loan_Amount_Term']\n",
    "test_eda['EMI'] = test_eda['LoanAmount']/test_eda['Loan_Amount_Term']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_eda['BalanceIncome'] = train_eda['TotalIncome'] - train_eda['EMI']*1000 - (train_eda['Dependents']+1.0+train_eda['CoapplicantIncome'].apply(lambda x: 1.0 if x > 0.0 else 0.0))*0.05*train_eda['TotalIncome'] \n",
    "test_eda['BalanceIncome'] = test_eda['TotalIncome'] - test_eda['EMI']*1000 - (test_eda['Dependents']+1.0+test_eda['CoapplicantIncome'].apply(lambda x: 1.0 if x > 0.0 else 0.0))*0.05*test_eda['TotalIncome'] \n",
    "\n",
    "train_eda['People'] = train_eda['Dependents']+1.0+train_eda['CoapplicantIncome'].apply(lambda x: 1.0 if x > 0.0 else 0.0)\n",
    "test_eda['People'] = test_eda['Dependents']+1.0+test_eda['CoapplicantIncome'].apply(lambda x: 1.0 if x > 0.0 else 0.0)\n",
    "\n",
    "train_eda.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_eda.copy()\n",
    "test = test_eda.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_heatmap = train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_heatmap.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_heatmap = train.drop(['People','TotalIncome_log'], axis=1)\n",
    "\n",
    "train_heatmap[\"Dependents\"].replace(\"3+\", \"3\", inplace=True)\n",
    "train_heatmap[\"Loan_Status\"].replace(\"N\", 0, inplace=True)\n",
    "train_heatmap[\"Loan_Status\"].replace(\"Y\", 1, inplace=True)\n",
    "train_heatmap[\"Gender\"].replace(\"Male\", 0, inplace=True)\n",
    "train_heatmap[\"Gender\"].replace(\"Female\", 1, inplace=True)\n",
    "train_heatmap[\"Married\"].replace(\"No\", 0, inplace=True)\n",
    "train_heatmap[\"Married\"].replace(\"Yes\", 1, inplace=True)\n",
    "train_heatmap[\"Education\"].replace(\"Graduate\", 1, inplace=True)\n",
    "train_heatmap[\"Education\"].replace(\"Not Graduate\", 0, inplace=True)\n",
    "train_heatmap[\"Self_Employed\"].replace(\"No\", 0, inplace=True)\n",
    "train_heatmap[\"Self_Employed\"].replace(\"Yes\", 1, inplace=True)\n",
    "train_heatmap[\"Property_Area\"].replace(\"Urban\", 2, inplace=True)\n",
    "train_heatmap[\"Property_Area\"].replace(\"Rural\", 0, inplace=True)\n",
    "train_heatmap[\"Property_Area\"].replace(\"Semiurban\", 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap = train_heatmap.corr()\n",
    "\n",
    "f, ax = plt.subplots(figsize = (9, 6))\n",
    "sns.heatmap(heatmap, vmax = 0.8, square = True, cmap = \"BuPu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Dependents'].replace(3.0,\"3\",inplace=True)\n",
    "train['Dependents'].replace(2.0,\"2\",inplace=True)\n",
    "train['Dependents'].replace(1.0,\"1\",inplace=True)\n",
    "train['Dependents'].replace(0.0,\"0\",inplace=True)\n",
    "\n",
    "test['Dependents'].replace(3.0,\"3\",inplace=True)\n",
    "test['Dependents'].replace(2.0,\"2\",inplace=True)\n",
    "test['Dependents'].replace(1.0,\"1\",inplace=True)\n",
    "test['Dependents'].replace(0.0,\"0\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(['ApplicantIncome', 'CoapplicantIncome','LoanAmount','Loan_Amount_Term'], axis=1)\n",
    "test = test.drop(['Loan_ID','ApplicantIncome', 'CoapplicantIncome','LoanAmount','Loan_Amount_Term'], axis=1)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(['Loan_Status'],axis=1)\n",
    "y = train['Loan_Status']\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_before_dummy = train.copy()\n",
    "test_before_dummy = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.get_dummies(train)\n",
    "test = pd.get_dummies(test)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_score = 0\n",
    "i = 1\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5, random_state=1, shuffle=True)\n",
    "\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "    print('\\n{} of kfold {}'.format(i, kf.n_splits))\n",
    "\n",
    "    xtr, xvl = X.loc[train_index], X.loc[test_index]\n",
    "    ytr, yvl = y.loc[train_index], y.loc[test_index]\n",
    "\n",
    "    model = LogisticRegression(random_state=1)\n",
    "\n",
    "    model.fit(xtr, ytr)\n",
    "\n",
    "    y_pred_vl = model.predict(xvl)\n",
    "\n",
    "    score = accuracy_score(yvl, y_pred_vl)\n",
    "    print(\"accuracy_score\", score)\n",
    "\n",
    "    i+=1\n",
    "\n",
    "    y_pred_test = model.predict(test)\n",
    "    pred = model.predict_proba(xvl)[:, 1]\n",
    "\n",
    "    sum_score += score\n",
    "\n",
    "print(\"\\nMean validation accuracy is:\", sum_score/(i-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['Loan_Status'] = y_pred_test\n",
    "submission['Loan_ID'] = test_original['Loan_ID']\n",
    "\n",
    "submission.Loan_Status.replace(1, 'Y', inplace=True)\n",
    "submission.Loan_Status.replace(0, 'N', inplace=True)\n",
    "\n",
    "pd.DataFrame(submission, columns=['Loan_ID', 'Loan_Status']).to_csv('new_log_reg.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramgrid = {'max_depth' : list(range(1, 20, 2)), 'n_estimators' : list(range(1, 200, 20))}\n",
    "\n",
    "gridSearch = GridSearchCV(RandomForestClassifier(random_state=1), paramgrid)\n",
    "\n",
    "X_train, X_cv, y_train, y_cv = train_test_split(X, y, test_size = 0.3)\n",
    "\n",
    "#Fit the grid search model\n",
    "gridSearch.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_score = 0\n",
    "i = 1\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5, random_state=1, shuffle=True)\n",
    "\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "    print('\\n{} of kfold {}'.format(i, kf.n_splits))\n",
    "\n",
    "    xtr, xvl = X.loc[train_index], X.loc[test_index]\n",
    "    ytr, yvl = y[train_index], y[test_index]\n",
    "\n",
    "    model = RandomForestClassifier(random_state=1, max_depth=3, n_estimators=21)\n",
    "\n",
    "    model.fit(xtr, ytr)\n",
    "\n",
    "    y_pred_vl = model.predict(xvl)\n",
    "\n",
    "    score = accuracy_score(yvl, y_pred_vl)\n",
    "    print(\"accuracy_score\", score)\n",
    "\n",
    "    i+=1\n",
    "\n",
    "    y_pred_test = model.predict(test)\n",
    "    pred = model.predict_proba(xvl)[:, 1]\n",
    "\n",
    "    sum_score += score\n",
    "\n",
    "print(\"\\nMean validation accuracy is:\", sum_score/(i-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['Loan_Status'] = y_pred_test\n",
    "submission['Loan_ID'] = test_original['Loan_ID']\n",
    "\n",
    "submission.Loan_Status.replace(1, 'Y', inplace=True)\n",
    "submission.Loan_Status.replace(0, 'N', inplace=True)\n",
    "\n",
    "pd.DataFrame(submission, columns=['Loan_ID', 'Loan_Status']).to_csv('new_random_forest.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Lets try removing unnecessary features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_before_dummy.copy()\n",
    "test = test_before_dummy.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(['Gender','Self_Employed','TotalIncome','People','Loan_Status','Dependents'],axis=1)\n",
    "test = test.drop(['Gender','Self_Employed','TotalIncome','People','Dependents'],axis=1)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.copy()\n",
    "train = pd.get_dummies(train)\n",
    "test = pd.get_dummies(test)\n",
    "X = pd.get_dummies(X)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_score = 0\n",
    "i = 1\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5, random_state=1, shuffle=True)\n",
    "\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "    print('\\n{} of kfold {}'.format(i, kf.n_splits))\n",
    "\n",
    "    xtr, xvl = X.loc[train_index], X.loc[test_index]\n",
    "    ytr, yvl = y.loc[train_index], y.loc[test_index]\n",
    "\n",
    "    model = LogisticRegression(random_state=1)\n",
    "\n",
    "    model.fit(xtr, ytr)\n",
    "\n",
    "    y_pred_vl = model.predict(xvl)\n",
    "\n",
    "    score = accuracy_score(yvl, y_pred_vl)\n",
    "    print(\"accuracy_score\", score)\n",
    "\n",
    "    i+=1\n",
    "\n",
    "    y_pred_test = model.predict(test)\n",
    "    pred = model.predict_proba(xvl)[:, 1]\n",
    "\n",
    "    sum_score += score\n",
    "\n",
    "print(\"\\nMean validation accuracy is:\", sum_score/(i-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['Loan_Status'] = y_pred_test\n",
    "submission['Loan_ID'] = test_original['Loan_ID']\n",
    "\n",
    "submission.Loan_Status.replace(1, 'Y', inplace=True)\n",
    "submission.Loan_Status.replace(0, 'N', inplace=True)\n",
    "\n",
    "pd.DataFrame(submission, columns=['Loan_ID', 'Loan_Status']).to_csv('new_log_reg1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramgrid = {'max_depth' : list(range(1, 20, 2)), 'n_estimators' : list(range(1, 200, 20))}\n",
    "\n",
    "gridSearch = GridSearchCV(RandomForestClassifier(random_state=1), paramgrid)\n",
    "\n",
    "X_train, X_cv, y_train, y_cv = train_test_split(X, y, test_size = 0.3)\n",
    "\n",
    "#Fit the grid search model\n",
    "gridSearch.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_score = 0\n",
    "i = 1\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5, random_state=1, shuffle=True)\n",
    "\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "    print('\\n{} of kfold {}'.format(i, kf.n_splits))\n",
    "\n",
    "    xtr, xvl = X.loc[train_index], X.loc[test_index]\n",
    "    ytr, yvl = y[train_index], y[test_index]\n",
    "\n",
    "    model = RandomForestClassifier(random_state=1, max_depth=5, n_estimators=121)\n",
    "\n",
    "    model.fit(xtr, ytr)\n",
    "\n",
    "    y_pred_vl = model.predict(xvl)\n",
    "\n",
    "    score = accuracy_score(yvl, y_pred_vl)\n",
    "    print(\"accuracy_score\", score)\n",
    "\n",
    "    i+=1\n",
    "\n",
    "    y_pred_test = model.predict(test)\n",
    "    pred = model.predict_proba(xvl)[:, 1]\n",
    "\n",
    "    sum_score += score\n",
    "\n",
    "print(\"\\nMean validation accuracy is:\", sum_score/(i-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = pd.Series(model.feature_importances_, index = X.columns)\n",
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances.plot(kind='barh', figsize=(12,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['Loan_Status'] = y_pred_test\n",
    "submission['Loan_ID'] = test_original['Loan_ID']\n",
    "\n",
    "submission.Loan_Status.replace(1, 'Y', inplace=True)\n",
    "submission.Loan_Status.replace(0, 'N', inplace=True)\n",
    "\n",
    "pd.DataFrame(submission, columns=['Loan_ID', 'Loan_Status']).to_csv('new_random_forest1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets try different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.svm import SVC \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "  \n",
    "from sklearn import metrics \n",
    "  \n",
    "knn = KNeighborsClassifier(n_neighbors=3) \n",
    "rfc = RandomForestClassifier(n_estimators = 121, \n",
    "                             criterion = 'entropy') \n",
    "svc = SVC() \n",
    "lc = LogisticRegression() \n",
    "\n",
    "X = X_old.copy()\n",
    "y = y_old.copy()\n",
    "test = test_old.copy()\n",
    "train = train_old.copy()\n",
    "\n",
    "X_train, X_cv, y_train, y_cv = train_test_split(X, y, test_size = 0.4)\n",
    "\n",
    "# making predictions on the training set \n",
    "for clf in (rfc, knn, svc,lc):\n",
    "    clf.fit(X_train, y_train)\n",
    "    Y_pred = clf.predict(X_cv) \n",
    "    print(\"Accuracy score of \", \n",
    "          clf.__class__.__name__, \n",
    "          \"=\",100*metrics.accuracy_score(y_cv,  \n",
    "                                         Y_pred))\n",
    "    \n",
    "\n",
    "# making predictions on the testing set \n",
    "for clf in (rfc, knn, svc,lc):\n",
    "    # clf.fit(X_cv, y_cv)\n",
    "    y_pred_test = clf.predict(test)\n",
    "    \n",
    "    submission['Loan_Status'] = y_pred_test\n",
    "    submission['Loan_ID'] = test_original['Loan_ID']\n",
    "\n",
    "    submission.Loan_Status.replace(1, 'Y', inplace=True)\n",
    "    submission.Loan_Status.replace(0, 'N', inplace=True)\n",
    "\n",
    "    pd.DataFrame(submission, columns=['Loan_ID', 'Loan_Status']).to_csv(clf.__class__.__name__+'.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
