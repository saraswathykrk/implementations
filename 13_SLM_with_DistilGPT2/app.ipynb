{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sara/Documents/GitHub/implementations/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/sara/Documents/GitHub/implementations/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "import pandas as pd\n",
    "import ast\n",
    "import datasets\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input', 'reference', 'output', 'instruction'],\n",
       "        num_rows: 10110\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "dataset = load_dataset(\"prognosis/symptoms_disease_v1\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>Disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What are the symptoms of hypertensive  disease?</td>\n",
       "      <td>The following are the symptoms of hypertensive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am having the following symptoms: pain  ches...</td>\n",
       "      <td>The symptoms listed indicates that the patient...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What are the symptoms of diabetes?</td>\n",
       "      <td>The following are the symptoms of diabetes: po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I am having the following symptoms: polyuria, ...</td>\n",
       "      <td>The symptoms listed indicates that the patient...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What are the symptoms of depressive disorder?</td>\n",
       "      <td>The following are the symptoms of depressive d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Input  \\\n",
       "0    What are the symptoms of hypertensive  disease?   \n",
       "1  I am having the following symptoms: pain  ches...   \n",
       "2                 What are the symptoms of diabetes?   \n",
       "3  I am having the following symptoms: polyuria, ...   \n",
       "4      What are the symptoms of depressive disorder?   \n",
       "\n",
       "                                             Disease  \n",
       "0  The following are the symptoms of hypertensive...  \n",
       "1  The symptoms listed indicates that the patient...  \n",
       "2  The following are the symptoms of diabetes: po...  \n",
       "3  The symptoms listed indicates that the patient...  \n",
       "4  The following are the symptoms of depressive d...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to a pandas dataframe\n",
    "updated_data = [{'Input': item['instruction'], 'Disease': item['output']} for item in dataset['train']]\n",
    "df = pd.DataFrame(updated_data)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    # If Apple Silicon, set to 'mps' - otherwise 'cpu' (not advised)\n",
    "    try:\n",
    "        device = torch.device('mps')\n",
    "    except Exception:\n",
    "        device = torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-5): 6 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2SdpaAttention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The tokenizer turns texts to numbers (and vice-versa)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('distilgpt2')\n",
    "\n",
    "# The transformer\n",
    "model = GPT2LMHeadModel.from_pretrained('distilgpt2').to(device)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Prep\n",
    "class LanguageDataset(Dataset):\n",
    "    \"\"\"\n",
    "    An extension of the Dataset object to:\n",
    "      - Make training loop cleaner\n",
    "      - Make ingestion easier from pandas df's\n",
    "    \"\"\"\n",
    "    def __init__(self, df, tokenizer):\n",
    "        self.labels = df.columns\n",
    "        self.data = df.to_dict(orient='records')\n",
    "        self.tokenizer = tokenizer\n",
    "        x = self.fittest_max_length(df)  # Fix here\n",
    "        self.max_length = x\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data[idx][self.labels[0]]\n",
    "        y = self.data[idx][self.labels[1]]\n",
    "        text = f\"{x} | {y}\"\n",
    "        tokens = self.tokenizer.encode_plus(text, return_tensors='pt', max_length=128, padding='max_length', truncation=True)\n",
    "        return tokens\n",
    "\n",
    "    def fittest_max_length(self, df):  # Fix here\n",
    "        \"\"\"\n",
    "        Smallest power of two larger than the longest term in the data set.\n",
    "        Important to set up max length to speed training time.\n",
    "        \"\"\"\n",
    "        max_length = max(len(max(df[self.labels[0]], key=len)), len(max(df[self.labels[1]], key=len)))\n",
    "        x = 2\n",
    "        while x < max_length: x = x * 2\n",
    "        return x\n",
    "\n",
    "# Cast the Huggingface data set as a LanguageDataset we defined above\n",
    "data_sample = LanguageDataset(df, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(data_sample))\n",
    "valid_size = len(data_sample) - train_size\n",
    "train_data, valid_data = random_split(data_sample, [train_size, valid_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of epochs\n",
    "num_epochs = 2\n",
    "# Model params\n",
    "BATCH_SIZE = 8\n",
    "# Training parameters\n",
    "batch_size = BATCH_SIZE\n",
    "model_name = 'distilgpt2'\n",
    "gpu = 0\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-4)\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "# Init a results dataframe\n",
    "results = pd.DataFrame(columns=['epoch', 'transformer', 'batch_size', 'gpu',\n",
    "                                'training_loss', 'validation_loss', 'epoch_duration_sec'])\n",
    "\n",
    "# Make the iterators\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valid_loader = DataLoader(valid_data, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/2 Batch Size: 8, Transformer: distilgpt2: 100%|██████████| 1011/1011 [11:51<00:00,  1.42it/s, Training Loss=0.0595]\n",
      "Validation Epoch 1/2: 100%|██████████| 253/253 [00:54<00:00,  4.64it/s, Validation Loss=0.0468]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Validation Loss: 0.07673904445508252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/2 Batch Size: 8, Transformer: distilgpt2: 100%|██████████| 1011/1011 [13:09<00:00,  1.28it/s, Training Loss=0.0667]\n",
      "Validation Epoch 2/2: 100%|██████████| 253/253 [00:54<00:00,  4.67it/s, Validation Loss=0.0484]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Validation Loss: 0.07084486230088788\n"
     ]
    }
   ],
   "source": [
    "# The training loop\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()  # Start the timer for the epoch\n",
    "\n",
    "    # Training\n",
    "    ## This line tells the model we're in 'learning mode'\n",
    "    model.train()\n",
    "    epoch_training_loss = 0\n",
    "    train_iterator = tqdm(train_loader, desc=f\"Training Epoch {epoch+1}/{num_epochs} Batch Size: {batch_size}, Transformer: {model_name}\")\n",
    "    for batch in train_iterator:\n",
    "        optimizer.zero_grad()\n",
    "        inputs = batch['input_ids'].squeeze(1).to(device)\n",
    "        targets = inputs.clone()\n",
    "        outputs = model(input_ids=inputs, labels=targets)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_iterator.set_postfix({'Training Loss': loss.item()})\n",
    "        epoch_training_loss += loss.item()\n",
    "    avg_epoch_training_loss = epoch_training_loss / len(train_iterator)\n",
    "\n",
    "    # Validation\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    epoch_validation_loss = 0\n",
    "    total_loss = 0\n",
    "    valid_iterator = tqdm(valid_loader, desc=f\"Validation Epoch {epoch+1}/{num_epochs}\")\n",
    "    with torch.no_grad():\n",
    "        for batch in valid_iterator:\n",
    "            inputs = batch['input_ids'].squeeze(1).to(device)\n",
    "            targets = inputs.clone()\n",
    "            outputs = model(input_ids=inputs, labels=targets)\n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.item()  # Convert tensor to scalar\n",
    "            valid_iterator.set_postfix({'Validation Loss': loss.item()})\n",
    "            epoch_validation_loss += loss.item()\n",
    "\n",
    "    avg_epoch_validation_loss = epoch_validation_loss / len(valid_loader)\n",
    "\n",
    "    end_time = time.time()  # End the timer for the epoch\n",
    "    epoch_duration_sec = end_time - start_time  # Calculate the duration in seconds\n",
    "\n",
    "    new_row = {'transformer': model_name,\n",
    "               'batch_size': batch_size,\n",
    "               'gpu': gpu,\n",
    "               'epoch': epoch+1,\n",
    "               'training_loss': avg_epoch_training_loss,\n",
    "               'validation_loss': avg_epoch_validation_loss,\n",
    "               'epoch_duration_sec': epoch_duration_sec}  # Add epoch_duration to the dataframe\n",
    "\n",
    "    results.loc[len(results)] = new_row\n",
    "    print(f\"Epoch: {epoch+1}, Validation Loss: {total_loss/len(valid_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are the symptoms of Chicken pox? | The following are the symptoms of Chicken pox: itching, skin rash, fatigue, lethargy, high fever, headache, loss of appetite, mild fever, swelled lymph nodes, mala\n"
     ]
    }
   ],
   "source": [
    "# Define the input string\n",
    "input_str = \"What are the symptoms of Chicken pox?\"\n",
    "\n",
    "# Encode the input string with padding and attention mask\n",
    "encoded_input = tokenizer.encode_plus(\n",
    "    input_str,\n",
    "    return_tensors='pt',\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=50  # Adjust max_length as needed\n",
    ")\n",
    "\n",
    "# Move tensors to the appropriate device\n",
    "input_ids = encoded_input['input_ids'].to(device)\n",
    "attention_mask = encoded_input['attention_mask'].to(device)\n",
    "\n",
    "# Set the pad_token_id to the tokenizer's eos_token_id\n",
    "pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "# Generate the output\n",
    "output = model.generate(\n",
    "    input_ids,\n",
    "    attention_mask=attention_mask,\n",
    "    max_length=50,  # Adjust max_length as needed\n",
    "    num_return_sequences=1,\n",
    "    do_sample=True,\n",
    "    top_k=8,\n",
    "    top_p=0.95,\n",
    "    temperature=0.5,\n",
    "    repetition_penalty=1.2,\n",
    "    pad_token_id=pad_token_id\n",
    ")\n",
    "\n",
    "# Decode and print the output\n",
    "decoded_output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(decoded_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-Fine-Tuning Response:\n",
      "What are the symptoms of Chicken pox?\n",
      "The most common cause is chickenpox. It causes a small amount (about 1-3 times) of fever, which can be fatal to people with an infected immune system or other health problems such as\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "# Load pre-trained DistilGPT-2 tokenizer and model\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"distilgpt2\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"distilgpt2\")\n",
    "\n",
    "# Set the padding token to the end-of-sequence token (common practice for GPT-2-based models)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Define the input query\n",
    "input_query = \"What are the symptoms of Chicken pox?\"\n",
    "\n",
    "# Tokenize the input query\n",
    "input_tokens = tokenizer.encode_plus(\n",
    "    input_query,\n",
    "    return_tensors=\"pt\",\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=50  # Adjust max_length if needed\n",
    ")\n",
    "\n",
    "# Generate response using the pre-trained model\n",
    "output_tokens = model.generate(\n",
    "    input_ids=input_tokens[\"input_ids\"],\n",
    "    attention_mask=input_tokens[\"attention_mask\"],\n",
    "    max_length=50,  # Adjust max_length if needed\n",
    "    num_return_sequences=1,\n",
    "    do_sample=True,  # Sampling adds randomness for diverse outputs\n",
    "    top_k=8,  # Keep top 8 most probable tokens at each step\n",
    "    top_p=0.95,  # Consider tokens with a cumulative probability of 0.95\n",
    "    temperature=0.7,  # Adjust temperature for response diversity\n",
    "    repetition_penalty=1.2,  # Penalize repetitive token generations\n",
    "    pad_token_id=tokenizer.pad_token_id  # Handle padding gracefully\n",
    ")\n",
    "\n",
    "# Decode the generated output to human-readable text\n",
    "decoded_output = tokenizer.decode(output_tokens[0], skip_special_tokens=True)\n",
    "\n",
    "# Print the results\n",
    "print(\"Pre-Fine-Tuning Response:\")\n",
    "print(decoded_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
